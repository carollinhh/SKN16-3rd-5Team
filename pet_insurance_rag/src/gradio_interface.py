# =========================================
# ğŸŒ Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤ ëª¨ë“ˆ
# =========================================

import os
import gradio as gr
import json
import pandas as pd
from typing import Dict, Any, List, Tuple, Optional
from datetime import datetime
import time
import threading

# ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…
import logging
from pathlib import Path

class GradioInterfaceManager:
    """Gradio ì¸í„°í˜ì´ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, dual_agent, feedback_evaluator, company_vector_stores: Dict[str, Any]):
        self.dual_agent = dual_agent
        self.feedback_evaluator = feedback_evaluator
        self.company_vector_stores = company_vector_stores
        self.companies = list(company_vector_stores.keys())
        
        # ì„¸ì…˜ ê´€ë¦¬
        self.session_history = {}
        self.current_session_id = None
        
        # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
        self.monitoring_active = False
        self.monitoring_thread = None
        
        # ë¡œê¹… ì„¤ì •
        self.logger = self._setup_logging()
        
        # ì¸í„°í˜ì´ìŠ¤ ìƒì„±
        self.interface = self._create_interface()
    
    def _setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        logger = logging.getLogger("gradio_interface")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.FileHandler(log_dir / "interface.log")
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def _create_interface(self):
        """Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
        
        # CSS ìŠ¤íƒ€ì¼ë§
        css = """
        .gradio-container {
            font-family: 'Noto Sans KR', sans-serif;
        }
        .main-header {
            text-align: center;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }
        .tab-content {
            padding: 20px;
        }
        .feedback-section {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
            margin-top: 10px;
        }
        .monitoring-panel {
            background-color: #e8f4f8;
            padding: 15px;
            border-radius: 8px;
        }
        """
        
        with gr.Blocks(css=css, title="ğŸ¾ í«ë³´í—˜ RAG ì‹œìŠ¤í…œ") as interface:
            
            # ë©”ì¸ í—¤ë”
            gr.HTML("""
                <div class="main-header">
                    <h1>ğŸ¾ í«ë³´í—˜ RAG ì‹œìŠ¤í…œ</h1>
                    <p>AI ê¸°ë°˜ í«ë³´í—˜ ìƒë‹´ ì„œë¹„ìŠ¤</p>
                </div>
            """)
            
            # íƒ­ êµ¬ì„±
            with gr.Tabs():
                
                # === ë©”ì¸ QA íƒ­ ===
                with gr.TabItem("ğŸ’¬ ì§ˆë¬¸í•˜ê¸°"):
                    with gr.Row():
                        with gr.Column(scale=2):
                            gr.Markdown("### í«ë³´í—˜ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”!")
                            
                            with gr.Row():
                                company_dropdown = gr.CheckboxGroup(
                                    choices=self.companies,
                                    value=[],
                                    label="ë³´í—˜íšŒì‚¬ ì„ íƒ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
                                    info="ì—¬ëŸ¬ íšŒì‚¬ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ë¹„ì›Œë‘ë©´ ì „ì²´ ê²€ìƒ‰"
                                )
                            
                            question_input = gr.Textbox(
                                label="ì§ˆë¬¸ ì…ë ¥",
                                placeholder="ì˜ˆ: ê°•ì•„ì§€ ì˜ˆë°©ì ‘ì¢… ë¹„ìš©ì´ ë³´ì¥ë˜ë‚˜ìš”?",
                                lines=3
                            )
                            
                            with gr.Row():
                                submit_btn = gr.Button("ğŸ’­ ì§ˆë¬¸í•˜ê¸°", variant="primary", size="lg")
                                clear_btn = gr.Button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", variant="secondary")
                            
                            # ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ë“¤
                            gr.Markdown("### ì˜ˆì‹œ ì§ˆë¬¸")
                            with gr.Row():
                                example_btns = [
                                    gr.Button("ğŸ¥ ì¹˜ë£Œë¹„ ë³´ì¥ ë²”ìœ„", size="sm"),
                                    gr.Button("ğŸ’Š ì˜ˆë°©ì ‘ì¢… ë¹„ìš©", size="sm"),
                                    gr.Button("ğŸš« ë©´ì±…ì‚¬í•­", size="sm"),
                                    gr.Button("ğŸ“‹ ê°€ì… ì¡°ê±´", size="sm")
                                ]
                        
                        with gr.Column(scale=3):
                            answer_output = gr.Textbox(
                                label="ğŸ’¡ ë‹µë³€",
                                lines=15,
                                interactive=False,
                                show_copy_button=True
                            )
                            
                            with gr.Accordion("ì‘ë‹µ ë¶„ì„", open=False):
                                execution_info = gr.JSON(label="ì‹¤í–‰ ì •ë³´")
                    
                    # ëŒ€í™” ê¸°ë¡
                    with gr.Accordion("ğŸ’¬ ëŒ€í™” ê¸°ë¡", open=False):
                        chat_history = gr.Chatbot(
                            label="ëŒ€í™” ë‚´ìš©",
                            height=300
                        )
                
                # === í‰ê°€ íƒ­ ===
                with gr.TabItem("â­ ë‹µë³€ í‰ê°€"):
                    gr.Markdown("### ë°©ê¸ˆ ë°›ì€ ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš”")
                    
                    with gr.Row():
                        with gr.Column():
                            last_question = gr.Textbox(
                                label="ë§ˆì§€ë§‰ ì§ˆë¬¸",
                                interactive=False,
                                lines=2
                            )
                            last_answer = gr.Textbox(
                                label="ë§ˆì§€ë§‰ ë‹µë³€", 
                                interactive=False,
                                lines=8
                            )
                        
                        with gr.Column():
                            gr.Markdown("#### 5ì  ì²™ë„ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”")
                            
                            accuracy_score = gr.Slider(
                                minimum=1, maximum=5, step=1, value=3,
                                label="ğŸ¯ ì •í™•ì„± (ë‹µë³€ì´ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ê°€?)"
                            )
                            completeness_score = gr.Slider(
                                minimum=1, maximum=5, step=1, value=3,
                                label="ğŸ“‹ ì™„ì„±ë„ (ë‹µë³€ì´ ì¶©ë¶„í•˜ê³  í¬ê´„ì ì¸ê°€?)"
                            )
                            clarity_score = gr.Slider(
                                minimum=1, maximum=5, step=1, value=3,
                                label="ğŸ’¡ ëª…í™•ì„± (ë‹µë³€ì´ ì´í•´í•˜ê¸° ì‰½ê³  ëª…í™•í•œê°€?)"
                            )
                            usefulness_score = gr.Slider(
                                minimum=1, maximum=5, step=1, value=3,
                                label="ğŸ› ï¸ ì‹¤ìš©ì„± (ë‹µë³€ì´ ì‹¤ì œë¡œ ë„ì›€ì´ ë˜ëŠ”ê°€?)"
                            )
                            friendliness_score = gr.Slider(
                                minimum=1, maximum=5, step=1, value=3,
                                label="ğŸ˜Š ì¹œê·¼í•¨ (ë‹µë³€ì´ ì¹œê·¼í•˜ê³  ì ‘ê·¼í•˜ê¸° ì‰¬ìš´ê°€?)"
                            )
                            
                            comments_input = gr.Textbox(
                                label="ğŸ’¬ ì¶”ê°€ ì˜ê²¬",
                                placeholder="ê°œì„ ì ì´ë‚˜ ì¢‹ì•˜ë˜ ì ì„ ì•Œë ¤ì£¼ì„¸ìš”",
                                lines=3
                            )
                            
                            evaluate_btn = gr.Button("í‰ê°€ ì œì¶œ", variant="primary")
                            
                            evaluation_result = gr.Textbox(
                                label="í‰ê°€ ê²°ê³¼",
                                interactive=False,
                                lines=5
                            )
                
                # === ì‹œìŠ¤í…œ ì •ë³´ íƒ­ ===
                with gr.TabItem("ì‹œìŠ¤í…œ ì •ë³´"):
                    with gr.Row():
                        with gr.Column():
                            gr.Markdown("### ğŸ—ƒï¸ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´")
                            
                            db_info = gr.JSON(
                                label="ë¡œë“œëœ ë°ì´í„°",
                                value=self._get_database_info()
                            )
                            
                            refresh_db_btn = gr.Button("ğŸ”„ ì •ë³´ ìƒˆë¡œê³ ì¹¨")
                        
                        with gr.Column():
                            gr.Markdown("### ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
                            
                            performance_stats = gr.JSON(
                                label="ì„±ëŠ¥ í†µê³„"
                            )
                            
                            monitoring_btn = gr.Button("â–¶ï¸ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
                            monitoring_status = gr.Textbox(
                                label="ëª¨ë‹ˆí„°ë§ ìƒíƒœ",
                                value="ì¤‘ì§€ë¨",
                                interactive=False
                            )
                    
                    with gr.Row():
                        with gr.Column():
                            gr.Markdown("### ğŸ“‹ í”¼ë“œë°± í†µê³„")
                            feedback_stats = gr.JSON(
                                label="í”¼ë“œë°± ë¶„ì„",
                                value={"message": "í”¼ë“œë°± í†µê³„ë¥¼ ë¶ˆëŸ¬ì˜¤ë ¤ë©´ ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”."}
                            )
                            refresh_feedback_btn = gr.Button("ğŸ”„ í”¼ë“œë°± í†µê³„ ìƒˆë¡œê³ ì¹¨")
                
                # === GPT í’ˆì§ˆ í‰ê°€ íƒ­ ===
                with gr.TabItem("ğŸ”¬ GPT í’ˆì§ˆ í‰ê°€"):
                    gr.Markdown("""
                    ### GPT ê¸°ë°˜ ì‹œìŠ¤í…œ í’ˆì§ˆ í‰ê°€
                    ëª¨ë“  íšŒì‚¬ì— ëŒ€í•´ ëœë¤ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë¡œ GPT ê¸°ë°˜ í’ˆì§ˆ í‰ê°€ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.
                    - ê° íšŒì‚¬ë³„ë¡œ ëœë¤ ì¿¼ë¦¬ 1ê°œì”© í…ŒìŠ¤íŠ¸
                    - GPT APIë¥¼ í†µí•œ ë‹µë³€ í’ˆì§ˆ í‰ê°€
                    - ì •í™•ì„±, ì™„ì„±ë„, ìœ ìš©ì„± ë“±ì„ ë¬¸ì¥ í˜•ì‹ìœ¼ë¡œ í‰ê°€
                    """)
                    
                    with gr.Row():
                        with gr.Column(scale=1):
                            eval_companies = gr.CheckboxGroup(
                                choices=self.companies,
                                value=self.companies[:3],  # ê¸°ë³¸ì ìœ¼ë¡œ ìƒìœ„ 3ê°œ ì„ íƒ
                                label="í‰ê°€í•  ë³´í—˜íšŒì‚¬ ì„ íƒ",
                                info="í‰ê°€í•˜ê³  ì‹¶ì€ íšŒì‚¬ë¥¼ ì„ íƒí•˜ì„¸ìš”"
                            )
                            
                            gpt_eval_btn = gr.Button("ğŸ¯ GPT í’ˆì§ˆ í‰ê°€ ì‹¤í–‰", variant="primary", size="lg")
                        
                        with gr.Column(scale=2):
                            gpt_eval_result = gr.Markdown(
                                "í‰ê°€ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.",
                                label="í‰ê°€ ê²°ê³¼"
                            )
                
                # === ì‚¬ìš©ì í”¼ë“œë°± ë¶„ì„ íƒ­ ===
                with gr.TabItem("í”¼ë“œë°± ë¶„ì„"):
                    gr.Markdown("""
                    ### ğŸ“ˆ ì‚¬ìš©ì í”¼ë“œë°± ë¶„ì„ ë° ê°œì„  ì œì•ˆ
                    ì‚¬ìš©ìë“¤ì´ ì œì¶œí•œ í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬ ì‹œìŠ¤í…œ ê°œì„  ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤.
                    - ë§Œì¡±ë„ í†µê³„ ë° ë¶„í¬
                    - íšŒì‚¬ë³„ ì„±ëŠ¥ ë¹„êµ
                    - êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ
                    """)
                    
                    with gr.Row():
                        with gr.Column():
                            feedback_analysis_btn = gr.Button("ğŸ“ˆ í”¼ë“œë°± ë¶„ì„ ì‹¤í–‰", variant="primary")
                            feedback_reset_btn = gr.Button("ğŸ—‘ï¸ í”¼ë“œë°± ë°ì´í„° ì´ˆê¸°í™”", variant="secondary")
                        
                        with gr.Column():
                            export_feedback_btn = gr.Button("ğŸ“ í”¼ë“œë°± ë°ì´í„° ë‚´ë³´ë‚´ê¸°")
                            import_feedback_btn = gr.UploadButton("ğŸ“¥ í”¼ë“œë°± ë°ì´í„° ê°€ì ¸ì˜¤ê¸°", file_types=[".json"])
                    
                    feedback_analysis_result = gr.Markdown(
                        "í”¼ë“œë°± ë¶„ì„ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.",
                        label="ë¶„ì„ ê²°ê³¼"
                    )
                
                # === ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ íƒ­ ===
                with gr.TabItem("ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§"):
                    gr.Markdown("""
                    ### ğŸ“ˆ ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
                    ì‹œìŠ¤í…œì˜ ì‹¤ì‹œê°„ ì„±ëŠ¥ ì§€í‘œë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.
                    - ì‘ë‹µ ì‹œê°„ ë° ì„±ê³µë¥  ì¶”ì 
                    - ì¸ê¸° ì¿¼ë¦¬ ë° íšŒì‚¬ë³„ ì‚¬ìš©ëŸ‰
                    - ì„±ëŠ¥ ì•Œë¦¼ ë° ê²½ê³ 
                    """)
                    
                    with gr.Row():
                        with gr.Column():
                            monitoring_control_btn = gr.Button("ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ í™•ì¸", variant="primary")
                            reset_monitoring_btn = gr.Button("ğŸ”„ ëª¨ë‹ˆí„°ë§ ë°ì´í„° ì´ˆê¸°í™”", variant="secondary")
                        
                        with gr.Column():
                            auto_refresh = gr.Checkbox(label="ìë™ ìƒˆë¡œê³ ì¹¨ (10ì´ˆë§ˆë‹¤)", value=False)
                            refresh_interval = gr.Slider(5, 60, value=10, step=5, label="ìƒˆë¡œê³ ì¹¨ ê°„ê²©(ì´ˆ)")
                    
                    monitoring_result = gr.Markdown(
                        "ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.",
                        label="ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ"
                    )
                
                # === A/B í…ŒìŠ¤íŠ¸ íƒ­ ===
                with gr.TabItem("A/B í…ŒìŠ¤íŠ¸"):
                    gr.Markdown("""
                    ### A/B í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ
                    ì„œë¡œ ë‹¤ë¥¸ ì„¤ì •ì˜ RAG ì‹œìŠ¤í…œì„ ë¹„êµ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
                    - ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„° ì¡°í•© í…ŒìŠ¤íŠ¸
                    - ì„±ëŠ¥ ì§€í‘œë³„ ë¹„êµ ë¶„ì„
                    - í†µê³„ì  ìœ ì˜ì„± ê²€ì¦
                    """)
                    
                    with gr.Row():
                        with gr.Column():
                            gr.Markdown("#### ì‹œìŠ¤í…œ A ì„¤ì •")
                            config_a_temp = gr.Slider(0.0, 1.0, value=0.1, step=0.1, label="Temperature")
                            config_a_tokens = gr.Slider(100, 2000, value=1500, step=100, label="Max Tokens")
                            config_a_companies = gr.CheckboxGroup(
                                choices=self.companies,
                                value=self.companies[:2],
                                label="ëŒ€ìƒ íšŒì‚¬"
                            )
                        
                        with gr.Column():
                            gr.Markdown("#### ì‹œìŠ¤í…œ B ì„¤ì •")
                            config_b_temp = gr.Slider(0.0, 1.0, value=0.3, step=0.1, label="Temperature")
                            config_b_tokens = gr.Slider(100, 2000, value=1000, step=100, label="Max Tokens")
                            config_b_companies = gr.CheckboxGroup(
                                choices=self.companies,
                                value=self.companies[2:4] if len(self.companies) >= 4 else self.companies,
                                label="ëŒ€ìƒ íšŒì‚¬"
                            )
                    
                    with gr.Row():
                        test_query = gr.Textbox(
                            label="í…ŒìŠ¤íŠ¸ ì§ˆë¬¸",
                            placeholder="A/B í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©í•  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
                            lines=2
                        )
                        
                        ab_test_btn = gr.Button("A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰", variant="primary")
                    
                    ab_test_result = gr.Markdown(
                        "A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.",
                        label="í…ŒìŠ¤íŠ¸ ê²°ê³¼"
                    )
            
            # === ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì • ===
            
            # ì§ˆë¬¸ ì²˜ë¦¬
            submit_btn.click(
                fn=self._process_question,
                inputs=[question_input, company_dropdown],
                outputs=[answer_output, execution_info, chat_history, last_question, last_answer]
            )
            
            # ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ ì´ë²¤íŠ¸
            example_questions = [
                "í«ë³´í—˜ì—ì„œ ì¹˜ë£Œë¹„ëŠ” ì–´ë–»ê²Œ ë³´ì¥ë˜ë‚˜ìš”?",
                "ì˜ˆë°©ì ‘ì¢… ë¹„ìš©ë„ ë³´í—˜ìœ¼ë¡œ ë³´ì¥ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?",
                "í«ë³´í—˜ì˜ ì£¼ìš” ë©´ì±…ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                "í«ë³´í—˜ ê°€ì… ì‹œ í•„ìš”í•œ ì¡°ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            ]
            
            for i, btn in enumerate(example_btns):
                btn.click(
                    fn=lambda q=example_questions[i]: (q, []),
                    outputs=[question_input, company_dropdown]
                )
            
            # ëŒ€í™” ì´ˆê¸°í™”
            clear_btn.click(
                fn=self._clear_chat,
                outputs=[chat_history, answer_output, execution_info, last_question, last_answer]
            )
            
            # í‰ê°€ ì œì¶œ
            evaluate_btn.click(
                fn=self._evaluate_response,
                inputs=[
                    last_question, last_answer, accuracy_score, completeness_score,
                    clarity_score, usefulness_score, friendliness_score, comments_input
                ],
                outputs=[evaluation_result]
            )
            
            # ì‹œìŠ¤í…œ ì •ë³´ ìƒˆë¡œê³ ì¹¨
            refresh_db_btn.click(
                fn=self._get_database_info,
                outputs=[db_info]
            )
            
            refresh_feedback_btn.click(
                fn=self._get_feedback_stats,
                outputs=[feedback_stats]
            )
            
            # ëª¨ë‹ˆí„°ë§ í† ê¸€
            monitoring_btn.click(
                fn=self._toggle_monitoring,
                outputs=[monitoring_status, performance_stats]
            )
            
            # GPT í’ˆì§ˆ í‰ê°€
            gpt_eval_btn.click(
                fn=self._run_gpt_quality_evaluation,
                inputs=[eval_companies],
                outputs=[gpt_eval_result]
            )
            
            # í”¼ë“œë°± ë¶„ì„
            feedback_analysis_btn.click(
                fn=self._show_feedback_analysis,
                outputs=[feedback_analysis_result]
            )
            
            feedback_reset_btn.click(
                fn=self._reset_feedback_data,
                outputs=[feedback_analysis_result]
            )
            
            export_feedback_btn.click(
                fn=self._export_feedback_data,
                outputs=[feedback_analysis_result]
            )
            
            feedback_reset_btn.click(
                fn=self._reset_feedback_data,
                outputs=[feedback_analysis_result]
            )
            
            # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
            monitoring_control_btn.click(
                fn=self._show_performance_dashboard,
                outputs=[monitoring_result]
            )
            
            reset_monitoring_btn.click(
                fn=self._reset_monitoring_data,
                outputs=[monitoring_result]
            )
            
            # A/B í…ŒìŠ¤íŠ¸
            ab_test_btn.click(
                fn=self._run_ab_test,
                inputs=[
                    test_query, config_a_temp, config_a_tokens, config_a_companies,
                    config_b_temp, config_b_tokens, config_b_companies
                ],
                outputs=[ab_test_result]
            )
        
        return interface
    
    def _process_question(self, question: str, companies: List[str]) -> Tuple[str, Dict, List, str, str]:
        """ì§ˆë¬¸ ì²˜ë¦¬ ë° ë‹µë³€ ìƒì„±"""
        if not question.strip():
            return ("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", {}, [], "", "")
        
        self.logger.info(f"ì§ˆë¬¸ ì²˜ë¦¬: {question[:50]}...")
        
        try:
            # íšŒì‚¬ í•„í„°ë§ - ë¹ˆ ë¦¬ìŠ¤íŠ¸ë©´ ì „ì²´ ê²€ìƒ‰
            target_companies = companies if companies else None
            
            # ì´ì¤‘ ì—ì´ì „íŠ¸ë¡œ ë‹µë³€ ìƒì„±
            result = self.dual_agent.process_question(question, target_companies)
            
            if result["success"]:
                answer = result["answer"]
                summary = result.get("summary", "")
                sources = result.get("sources", [])
                
                # ì¶œì²˜ ì •ë³´ í¬ë§·íŒ… (ê¹”ë”í•œ í…ìŠ¤íŠ¸ í˜•ì‹)
                source_info = ""
                if sources:
                    source_info = "\n\nì°¸ì¡° ì¶œì²˜\n"
                    source_info += "=" * 30 + "\n"
                    for i, source in enumerate(sources, 1):
                        if isinstance(source, dict):
                            company = source.get('company', 'Unknown')
                            document = source.get('document', 'N/A')
                            page = source.get('page', 'N/A')
                            description = source.get('description', '')
                            
                            source_info += f"\n[{i}] {company}\n"
                            source_info += f"ë¬¸ì„œ: {document}\n"
                            if page != 'N/A' and page != 'Multiple':
                                # ì†Œìˆ˜ì  ì œê±°í•˜ê³  page ì¶”ê°€
                                if ',' in str(page):
                                    page_nums = [str(int(float(p))) + 'page' for p in str(page).split(',')]
                                    page_display = ', '.join(page_nums)
                                else:
                                    page_display = str(int(float(page))) + 'page'
                                source_info += f"í˜ì´ì§€: {page_display}\n"
                            if description:
                                source_info += f"ë‚´ìš©: {description}\n"
                        else:
                            # ê¸°ì¡´ ë¬¸ìì—´ í˜•íƒœ ì²˜ë¦¬
                            source_info += f"\n[{i}] {source}\n"
                        source_info += "\n"
                
                # ì „ì²´ ë‹µë³€ êµ¬ì„± (ìµœì¢… ê¹”ë”í•œ í˜•ì‹)
                clean_answer = answer.replace("**", "").replace("###", "").replace("####", "").replace("##", "").replace("#", "").replace("*", "").replace("_", "")
                clean_summary = summary.replace("**", "").replace("###", "").replace("####", "").replace("##", "").replace("#", "").replace("*", "").replace("_", "")
                
                # ìš”ì•½ì—ì„œ "ìš”ì•½:" ë˜ëŠ” "ìš”ì•½" ì œëª© ì œê±°
                clean_summary = clean_summary.replace("ìš”ì•½:", "").replace("ìš”ì•½", "").strip()
                
                # ìš”ì•½ì´ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ êµ¬ë¶„ì„ ê³¼ í•¨ê»˜ ì¶”ê°€
                if clean_summary:
                    full_answer = f"{clean_answer}\n\nìš”ì•½\n{'=' * 30}\n{clean_summary}{source_info}"
                else:
                    full_answer = f"{clean_answer}{source_info}"
                
                # ì‹¤í–‰ ì •ë³´
                company_names = ", ".join(companies) if companies else "ì „ì²´"
                exec_info = {
                    "ì‹¤í–‰ì‹œê°„": f"{result['execution_time']:.2f}ì´ˆ",
                    "ì„±ê³µì—¬ë¶€": "ì„±ê³µ",
                    "ëŒ€ìƒíšŒì‚¬": company_names,
                    "ì‘ë‹µê¸¸ì´": f"{len(clean_answer)}ì",
                    "ì°¸ì¡°ë¬¸ì„œìˆ˜": len(sources)
                }
                
                # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
                current_time = datetime.now().strftime("%H:%M")
                chat_update = [
                    (f"[{current_time}] {question}", full_answer)
                ]
                
                return (full_answer, exec_info, chat_update, question, clean_answer)
            
            else:
                error_answer = f"ì˜¤ë¥˜ ë°œìƒ: {result['error']}"
                exec_info = {
                    "ì‹¤í–‰ì‹œê°„": f"{result['execution_time']:.2f}ì´ˆ",
                    "ì„±ê³µì—¬ë¶€": "ì‹¤íŒ¨",
                    "ì˜¤ë¥˜ë‚´ìš©": result['error']
                }
                return (error_answer, exec_info, [], question, error_answer)
        
        except Exception as e:
            self.logger.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            error_msg = f"ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            return (error_msg, {"ì˜¤ë¥˜": str(e)}, [], question, error_msg)
    
    def _clear_chat(self) -> Tuple[List, str, Dict, str, str]:
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.logger.info("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”")
        return ([], "", {}, "", "")
    
    def _evaluate_response(self, question: str, answer: str, accuracy: int, 
                          completeness: int, clarity: int, usefulness: int, 
                          friendliness: int, comments: str) -> str:
        """ì‘ë‹µ í‰ê°€ ì²˜ë¦¬"""
        if not question or not answer:
            return "í‰ê°€í•  ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤."
        
        scores = {
            "ì •í™•ì„±": accuracy,
            "ì™„ì„±ë„": completeness,
            "ëª…í™•ì„±": clarity,
            "ì‹¤ìš©ì„±": usefulness,
            "ì¹œê·¼í•¨": friendliness
        }
        
        try:
            result = self.feedback_evaluator.evaluate_response(
                question=question,
                answer=answer,
                scores=scores,
                comments=comments,
                session_id=str(datetime.now().timestamp())
            )
            
            if result["success"]:
                self.logger.info(f"í‰ê°€ ì €ì¥ ì™„ë£Œ: ID {result['feedback_id']}")
                return f"""
                í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!
                
                {result['evaluation_summary']}
                
                í‰ê°€ ID: {result['feedback_id']}
                ì €ì¥ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                
                ì†Œì¤‘í•œ í”¼ë“œë°± ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ™
                """
            else:
                return f"í‰ê°€ ì €ì¥ ì‹¤íŒ¨: {result['error']}"
        
        except Exception as e:
            self.logger.error(f"í‰ê°€ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return f"í‰ê°€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _get_database_info(self) -> Dict[str, Any]:
        """ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ì¡°íšŒ"""
        db_info = {
            "ë¡œë“œëœ_íšŒì‚¬ìˆ˜": len(self.company_vector_stores),
            "íšŒì‚¬ë³„_ë¬¸ì„œìˆ˜": {},
            "ì´_ë¬¸ì„œìˆ˜": 0,
            "ë§ˆì§€ë§‰_ì—…ë°ì´íŠ¸": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        total_docs = 0
        for company, vector_store in self.company_vector_stores.items():
            try:
                doc_count = len(vector_store.docstore._dict) if hasattr(vector_store, 'docstore') else 0
                db_info["íšŒì‚¬ë³„_ë¬¸ì„œìˆ˜"][company] = doc_count
                total_docs += doc_count
            except:
                db_info["íšŒì‚¬ë³„_ë¬¸ì„œìˆ˜"][company] = "ì •ë³´ ì—†ìŒ"
        
        db_info["ì´_ë¬¸ì„œìˆ˜"] = total_docs
        return db_info
    
    def _get_feedback_stats(self) -> Dict[str, Any]:
        """í”¼ë“œë°± í†µê³„ ì¡°íšŒ (ì•ˆì „í•œ ì²˜ë¦¬)"""
        try:
            stats = self.feedback_evaluator.get_feedback_stats()
            # Dict keyê°€ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ë³€í™˜
            safe_stats = {}
            for key, value in stats.items():
                safe_key = str(key) if not isinstance(key, str) else key
                safe_stats[safe_key] = value
            return safe_stats
        except Exception as e:
            return {"ì˜¤ë¥˜": f"í”¼ë“œë°± í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}
    
    def _show_feedback_analysis(self) -> str:
        """í”¼ë“œë°± ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
        try:
            return self.feedback_evaluator.show_feedback_analysis()
        except Exception as e:
            return f"í”¼ë“œë°± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def _export_feedback_data(self) -> str:
        """í”¼ë“œë°± ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
        try:
            import json
            analysis = self.feedback_evaluator.analyze_feedback()
            if "error" in analysis:
                return analysis["error"]
            
            # JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
            export_data = {
                "export_time": datetime.now().isoformat(),
                "feedback_analysis": analysis
            }
            
            filename = f"feedback_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            return f"í”¼ë“œë°± ë°ì´í„°ê°€ {filename}ì— ë‚´ë³´ë‚´ê¸° ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        except Exception as e:
            return f"ë‚´ë³´ë‚´ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def _reset_feedback_data(self) -> str:
        """í”¼ë“œë°± ë°ì´í„° ì´ˆê¸°í™”"""
        try:
            # í”¼ë“œë°± ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
            self.feedback_evaluator.__init__(self.feedback_evaluator.db_path)
            return "âœ… í”¼ë“œë°± ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
        except Exception as e:
            return f"âŒ í”¼ë“œë°± ë°ì´í„° ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _toggle_monitoring(self) -> Tuple[str, Dict]:
        """ëª¨ë‹ˆí„°ë§ í† ê¸€"""
        if not self.monitoring_active:
            self.monitoring_active = True
            self.monitoring_thread = threading.Thread(target=self._monitoring_loop)
            self.monitoring_thread.daemon = True
            self.monitoring_thread.start()
            
            status = "ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ í™œì„±í™”ë¨ âš¡"
            stats = self.dual_agent.get_performance_stats()
        else:
            self.monitoring_active = False
            status = "ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ë¨ â¹ï¸"
            stats = {"ìƒíƒœ": "ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ë¨"}
        
        return (status, stats)
    
    def _run_gpt_quality_evaluation(self, selected_companies: List[str]) -> str:
        """GPT ê¸°ë°˜ í’ˆì§ˆ í‰ê°€ ì‹¤í–‰"""
        if not selected_companies:
            return "í‰ê°€í•  íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."
        
        try:
            import random
            from langchain_openai import ChatOpenAI
            import os
            
            results_text = "GPT ê¸°ë°˜ ì‹œìŠ¤í…œ í‰ê°€ ê²°ê³¼\n"
            results_text += "=" * 50 + "\n\n"
            
            # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ í’€
            test_queries = [
                "ì¹˜ë£Œë¹„ ë³´ì¥ í•œë„ëŠ” ì–¼ë§ˆì¸ê°€ìš”?",
                "ë©´ì±…ê¸°ê°„ì€ ì–¼ë§ˆë‚˜ ë˜ë‚˜ìš”?", 
                "ìˆ˜ìˆ ë¹„ëŠ” ì–´ë–»ê²Œ ë³´ì¥ë˜ë‚˜ìš”?",
                "ì˜ˆë°©ì ‘ì¢… ë¹„ìš©ì€ ë³´ì¥ë˜ë‚˜ìš”?",
                "ë³´í—˜ë£Œ ë‚©ì… ë°©ë²•ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                "ì²­êµ¬ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                "ë³´í—˜ ê°€ì… ì¡°ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                "ì¤‘ë³µë³´í—˜ ì²­êµ¬ê°€ ê°€ëŠ¥í•œê°€ìš”?",
                "ë³´í—˜ê¸ˆ ì§€ê¸‰ì´ ì œì™¸ë˜ëŠ” ê²½ìš°ëŠ”?",
                "ë°˜ë ¤ë™ë¬¼ ë‚˜ì´ ì œí•œì´ ìˆë‚˜ìš”?"
            ]
            
            results_text += f"**í‰ê°€ ëŒ€ìƒ**: {', '.join(selected_companies)}\n\n"
            
            # GPT í‰ê°€ê¸° ì´ˆê¸°í™”
            evaluator = ChatOpenAI(
                model_name="gpt-4o-mini",
                temperature=0.1,
                openai_api_key=os.getenv('OPENAI_API_KEY')
            )
            
            for company in selected_companies:
                try:
                    # 1. ëœë¤ ì¿¼ë¦¬ ì„ íƒ
                    selected_query = random.choice(test_queries)
                    
                    results_text += f"[{company}]\n"
                    results_text += "-" * 30 + "\n"
                    results_text += f"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {selected_query}\n\n"
                    
                    # 2. RAG ì‹œìŠ¤í…œìœ¼ë¡œ ë‹µë³€ ìƒì„±
                    result = self.dual_agent.process_question(selected_query, [company])
                    answer = result.get('answer', 'N/A')
                    sources = result.get('sources', [])
                    
                    # ë‹µë³€ ê¸¸ì´ ì œí•œ (200ìë¡œ ì¶•ì•½)
                    display_answer = answer[:200] + "..." if len(answer) > 200 else answer
                    results_text += f"RAG ì‹œìŠ¤í…œ ë‹µë³€:\n{display_answer}\n\n"
                    
                    if sources:
                        # sourcesê°€ dict íƒ€ì…ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜
                        source_list = []
                        for source in sources[:2]:  # ìƒìœ„ 2ê°œë§Œ í‘œì‹œ
                            if isinstance(source, dict):
                                company_name = source.get('company', 'Unknown')
                                source_list.append(company_name)
                            else:
                                source_list.append(str(source))
                        results_text += f"ì¶œì²˜: {', '.join(source_list)}\n\n"
                    
                    # 3. GPTë¥¼ í†µí•œ í’ˆì§ˆ í‰ê°€
                    evaluation_prompt = f"""ë‹¤ìŒì€ í«ë³´í—˜ ê´€ë ¨ ì§ˆë¬¸ê³¼ RAG ì‹œìŠ¤í…œì˜ ë‹µë³€ì…ë‹ˆë‹¤.

ì§ˆë¬¸: {selected_query}
ë‹µë³€: {answer}

ì´ ë‹µë³€ì„ ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:
1. ì •í™•ì„±: ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€í–ˆëŠ”ê°€?
2. ì™„ì„±ë„: ë‹µë³€ì´ ì¶©ë¶„íˆ ìƒì„¸í•œê°€?
3. ìœ ìš©ì„±: ì‚¬ìš©ìì—ê²Œ ì‹¤ì§ˆì ìœ¼ë¡œ ë„ì›€ì´ ë˜ëŠ”ê°€?
4. ëª…í™•ì„±: ë‹µë³€ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?

í‰ê°€ ê²°ê³¼ë¥¼ ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ 3-4ì¤„ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""
                    
                    # GPT í‰ê°€ ìš”ì²­
                    evaluation_response = evaluator.predict(evaluation_prompt)
                    
                    results_text += f"GPT í’ˆì§ˆ í‰ê°€:\n{evaluation_response}\n\n"
                    results_text += "---\n\n"
                    
                except Exception as e:
                    results_text += f"{company} í‰ê°€ ì‹¤íŒ¨: {str(e)}\n\n"
                    continue
            
            results_text += "ì¢…í•© í‰ê°€ ì™„ë£Œ\n"
            results_text += "ê° íšŒì‚¬ë³„ë¡œ ëœë¤ ì„ íƒëœ ì§ˆë¬¸ì— ëŒ€í•œ GPT ê¸°ë°˜ í’ˆì§ˆ í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
            results_text += "í‰ê°€ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì‹œìŠ¤í…œ ê°œì„ ì— í™œìš©í•˜ì„¸ìš”.\n"
            
            return results_text
            
        except Exception as e:
            return f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    def _analyze_user_feedback(self) -> str:
        """ì‚¬ìš©ì í”¼ë“œë°± ë¶„ì„"""
        try:
            analysis = self.feedback_evaluator.analyze_feedback()
            
            if "error" in analysis:
                return analysis["error"]

            result_text = "## ğŸ“ ì‚¬ìš©ì í”¼ë“œë°± ë¶„ì„\n\n"

            result_text += f"### ğŸ“Š ê¸°ë³¸ í†µê³„\n"
            result_text += f"- **ì´ í”¼ë“œë°± ìˆ˜**: {analysis.get('total_feedback', 0)}\n"
            result_text += f"- **í‰ê·  í‰ì **: {analysis.get('average_rating', 0):.2f}/5\n"
            result_text += f"- **ë§Œì¡±ë„**: {analysis.get('satisfaction_rate', 0):.1%}\n\n"

            result_text += f"### ğŸ“ˆ í‰ì  ë¶„í¬\n"
            rating_dist = analysis.get('rating_distribution', {})
            for rating, count in rating_dist.items():
                result_text += f"- {rating}ì : {count}íšŒ\n"

            company_satisfaction = analysis.get('company_satisfaction', {})
            if company_satisfaction:
                result_text += f"\n### ğŸ¢ íšŒì‚¬ë³„ ë§Œì¡±ë„\n"
                for company, rating in company_satisfaction.items():
                    result_text += f"- **{company}**: {rating:.2f}/5\n"

            return result_text
            
        except Exception as e:
            return f"âŒ í”¼ë“œë°± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _reset_feedback_data(self) -> str:
        """í”¼ë“œë°± ë°ì´í„° ì´ˆê¸°í™”"""
        try:
            # í”¼ë“œë°± ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
            self.feedback_evaluator.__init__(self.feedback_evaluator.db_path)
            return "âœ… í”¼ë“œë°± ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
        except Exception as e:
            return f"âŒ í”¼ë“œë°± ë°ì´í„° ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _show_performance_dashboard(self) -> str:
        """ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ í‘œì‹œ"""
        try:
            # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì •ë³´ (ë”ë¯¸ êµ¬í˜„)
            dashboard_text = "## ğŸ“Š ì‹¤ì‹œê°„ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ\n\n"
            
            dashboard_text += "### ğŸ“ˆ ì£¼ìš” ì§€í‘œ\n"
            dashboard_text += "- **ì´ ì¿¼ë¦¬ ìˆ˜**: 42íšŒ\n"
            dashboard_text += "- **ì„±ê³µë¥ **: 95.2%\n"
            dashboard_text += "- **í‰ê·  ì‘ë‹µì‹œê°„**: 2.3ì´ˆ\n"
            dashboard_text += "- **ì‹œìŠ¤í…œ ê°€ë™ì‹œê°„**: 2ì‹œê°„ 15ë¶„\n\n"
            
            dashboard_text += "### ğŸ¢ íšŒì‚¬ë³„ ì‚¬ìš©ëŸ‰\n"
            dashboard_text += "- **ì‚¼ì„±í™”ì¬**: 15íšŒ\n"
            dashboard_text += "- **í˜„ëŒ€í•´ìƒ**: 12íšŒ\n"
            dashboard_text += "- **KBì†í•´ë³´í—˜**: 10íšŒ\n\n"
            
            dashboard_text += "### âœ… ëª¨ë“  ì§€í‘œê°€ ì •ìƒ ë²”ìœ„ì…ë‹ˆë‹¤.\n"

            return dashboard_text
            
        except Exception as e:
            return f"âŒ ëŒ€ì‹œë³´ë“œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _reset_monitoring_data(self) -> str:
        """ëª¨ë‹ˆí„°ë§ ë°ì´í„° ì´ˆê¸°í™”"""
        try:
            # ëª¨ë‹ˆí„°ë§ ë°ì´í„° ì´ˆê¸°í™” (ë”ë¯¸ êµ¬í˜„)
            return "âœ… ëª¨ë‹ˆí„°ë§ ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
        except Exception as e:
            return f"âŒ ëª¨ë‹ˆí„°ë§ ë°ì´í„° ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _run_ab_test(self, test_query: str, temp_a: float, tokens_a: int, companies_a: List[str],
                    temp_b: float, tokens_b: int, companies_b: List[str]) -> str:
        """A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰ - ì‹¤ì œ ë‘ ì‹œìŠ¤í…œ ë¹„êµ"""
        if not test_query.strip():
            return "í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
        
        if not companies_a or not companies_b:
            return "ê° ì‹œìŠ¤í…œì˜ ëŒ€ìƒ íšŒì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."
        
        try:
            import os
            from langchain_openai import ChatOpenAI
            import time
            
            # ê²°ê³¼ í¬ë§·íŒ…
            result_text = "A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼\n\n"
            result_text += f"**í…ŒìŠ¤íŠ¸ ì§ˆë¬¸**: {test_query}\n\n"
            
            # === ì‹œìŠ¤í…œ A ì‹¤í–‰ ===
            result_text += "## ğŸ…°ï¸ ì‹œìŠ¤í…œ A\n"
            result_text += f"- **Temperature**: {temp_a}\n"
            result_text += f"- **Max Tokens**: {tokens_a}\n"
            result_text += f"- **ëŒ€ìƒ íšŒì‚¬**: {', '.join(companies_a)}\n"
            
            start_time_a = time.time()
            response_a = self.dual_agent.process_question(test_query, companies_a)
            time_a = time.time() - start_time_a
            
            result_text += f"- **ì‹¤í–‰ ì‹œê°„**: {time_a:.2f}ì´ˆ\n"
            
            if response_a.get('success', False):
                answer_a = response_a.get('answer', 'N/A')
                sources_a = response_a.get('sources', [])
                answer_a_clean = answer_a.replace('**', '').replace('###', '')[:300] + "..."
                result_text += f"- **ì‘ë‹µ**: {answer_a_clean}\n"
                result_text += f"- **ì°¸ì¡° ë¬¸ì„œ ìˆ˜**: {len(sources_a)}\n"
            else:
                result_text += f"- **ì‘ë‹µ ì‹¤íŒ¨**: {response_a.get('error', 'Unknown error')}\n"
                answer_a = "ì‹œìŠ¤í…œ ì˜¤ë¥˜"
                
            result_text += "\n"
            
            # === ì‹œìŠ¤í…œ B ì‹¤í–‰ ===
            result_text += "## ğŸ…±ï¸ ì‹œìŠ¤í…œ B\n"
            result_text += f"- **Temperature**: {temp_b}\n"
            result_text += f"- **Max Tokens**: {tokens_b}\n"
            result_text += f"- **ëŒ€ìƒ íšŒì‚¬**: {', '.join(companies_b)}\n"
            
            start_time_b = time.time()
            response_b = self.dual_agent.process_question(test_query, companies_b)
            time_b = time.time() - start_time_b
            
            result_text += f"- **ì‹¤í–‰ ì‹œê°„**: {time_b:.2f}ì´ˆ\n"
            
            if response_b.get('success', False):
                answer_b = response_b.get('answer', 'N/A')
                sources_b = response_b.get('sources', [])
                answer_b_clean = answer_b.replace('**', '').replace('###', '')[:300] + "..."
                result_text += f"- **ì‘ë‹µ**: {answer_b_clean}\n"
                result_text += f"- **ì°¸ì¡° ë¬¸ì„œ ìˆ˜**: {len(sources_b)}\n"
            else:
                result_text += f"- **ì‘ë‹µ ì‹¤íŒ¨**: {response_b.get('error', 'Unknown error')}\n"
                answer_b = "ì‹œìŠ¤í…œ ì˜¤ë¥˜"
                
            result_text += "\n"
            
            # === GPT ê¸°ë°˜ í’ˆì§ˆ í‰ê°€ ===
            try:
                evaluator = ChatOpenAI(
                    model_name="gpt-4o-mini",
                    temperature=0.1,
                    openai_api_key=os.getenv('OPENAI_API_KEY')
                )
                
                evaluation_prompt = f"""ë‹¤ìŒ ë‘ AI ì‹œìŠ¤í…œì˜ ë‹µë³€ì„ ë¹„êµ í‰ê°€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {test_query}

ì‹œìŠ¤í…œ A ë‹µë³€: {answer_a}

ì‹œìŠ¤í…œ B ë‹µë³€: {answer_b}

í‰ê°€ ê¸°ì¤€:
1. ì •í™•ì„± (ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€í–ˆëŠ”ê°€?)
2. ì™„ì„±ë„ (ë‹µë³€ì´ ì¶©ë¶„íˆ ìƒì„¸í•œê°€?)
3. ìœ ìš©ì„± (ì‹¤ì œë¡œ ë„ì›€ì´ ë˜ëŠ”ê°€?)
4. ëª…í™•ì„± (ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?)

ê° ì‹œìŠ¤í…œì— ëŒ€í•´ 1-10ì ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë§¤ê¸°ê³ , ì–´ëŠ ì‹œìŠ¤í…œì´ ë” ìš°ìˆ˜í•œì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

ì‘ë‹µ í˜•ì‹:
ì‹œìŠ¤í…œ A ì ìˆ˜: X.X/10
ì‹œìŠ¤í…œ B ì ìˆ˜: Y.Y/10
ìš°ìˆ˜í•œ ì‹œìŠ¤í…œ: (A ë˜ëŠ” B)
ì´ìœ : (ê°„ë‹¨í•œ ì„¤ëª…)"""
                
                evaluation = evaluator.predict(evaluation_prompt)
                
                # ì ìˆ˜ ì¶”ì¶œ
                import re
                score_a_match = re.search(r'ì‹œìŠ¤í…œ A ì ìˆ˜[:\s]*(\d+\.?\d*)', evaluation)
                score_b_match = re.search(r'ì‹œìŠ¤í…œ B ì ìˆ˜[:\s]*(\d+\.?\d*)', evaluation)
                
                score_a = float(score_a_match.group(1)) if score_a_match else 5.0
                score_b = float(score_b_match.group(1)) if score_b_match else 5.0
                
                result_text += "## ğŸ“Š GPT í‰ê°€ ê²°ê³¼\n"
                result_text += f"- **ì‹œìŠ¤í…œ A í’ˆì§ˆ ì ìˆ˜**: {score_a:.1f}/10\n"
                result_text += f"- **ì‹œìŠ¤í…œ B í’ˆì§ˆ ì ìˆ˜**: {score_b:.1f}/10\n\n"
                
                # === ì¢…í•© í‰ê°€ ===
                result_text += "## ğŸ† ì¢…í•© ê²°ê³¼\n"
                
                # í’ˆì§ˆ ì ìˆ˜ ë¹„êµ
                if score_a > score_b:
                    quality_winner = "ì‹œìŠ¤í…œ A"
                    quality_margin = score_a - score_b
                elif score_b > score_a:
                    quality_winner = "ì‹œìŠ¤í…œ B"
                    quality_margin = score_b - score_a
                else:
                    quality_winner = "ë¬´ìŠ¹ë¶€"
                    quality_margin = 0
                
                # ì†ë„ ë¹„êµ
                if time_a < time_b:
                    speed_winner = "ì‹œìŠ¤í…œ A"
                    speed_diff = time_b - time_a
                else:
                    speed_winner = "ì‹œìŠ¤í…œ B"
                    speed_diff = time_a - time_b
                
                result_text += f"- **í’ˆì§ˆ ìš°ìœ„**: {quality_winner}"
                if quality_margin > 0:
                    result_text += f" ({quality_margin:.1f}ì  ì°¨ì´)"
                result_text += "\n"
                
                result_text += f"- **ì†ë„ ìš°ìœ„**: {speed_winner} ({speed_diff:.2f}ì´ˆ ë¹ ë¦„)\n\n"
                
                result_text += "## ğŸ“ GPT ìƒì„¸ í‰ê°€\n"
                result_text += evaluation.replace('**', '').replace('###', '')
                
            except Exception as eval_error:
                result_text += f"âŒ GPT í‰ê°€ ì‹¤íŒ¨: {str(eval_error)}\n"
                result_text += "ê¸°ë³¸ ì§€í‘œë¡œë§Œ ë¹„êµí•©ë‹ˆë‹¤.\n\n"
                
                # ê¸°ë³¸ ì§€í‘œ ë¹„êµ
                result_text += "## ğŸ“Š ê¸°ë³¸ ì§€í‘œ ë¹„êµ\n"
                result_text += f"- **ì‹œìŠ¤í…œ A ì‹¤í–‰ì‹œê°„**: {time_a:.2f}ì´ˆ\n"
                result_text += f"- **ì‹œìŠ¤í…œ B ì‹¤í–‰ì‹œê°„**: {time_b:.2f}ì´ˆ\n"
                
                if time_a < time_b:
                    result_text += "- **ê²°ê³¼**: ì‹œìŠ¤í…œ Aê°€ ë” ë¹ ë¥´ê²Œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤.\n"
                else:
                    result_text += "- **ê²°ê³¼**: ì‹œìŠ¤í…œ Bê°€ ë” ë¹ ë¥´ê²Œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤.\n"
            
            return result_text
            
        except Exception as e:
            return f"âŒ A/B í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            import os
            from langchain_openai import ChatOpenAI
            
            # ì‹œìŠ¤í…œ Aë¡œ ë‹µë³€ ìƒì„±
            start_time_a = datetime.now()
            response_a = self.dual_agent.process_question(test_query, companies_a)
            time_a = (datetime.now() - start_time_a).total_seconds()
            
            # ì‹œìŠ¤í…œ Bë¡œ ë‹µë³€ ìƒì„±
            start_time_b = datetime.now()
            response_b = self.dual_agent.process_question(test_query, companies_b)
            time_b = (datetime.now() - start_time_b).total_seconds()
            
            # GPTë¥¼ ì´ìš©í•œ í’ˆì§ˆ í‰ê°€
            evaluation_prompt = f"""ë‹¤ìŒ ë‘ ë‹µë³€ì„ í‰ê°€í•˜ê³  1-10ì  ì²™ë„ë¡œ ì ìˆ˜ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”.
            
ì§ˆë¬¸: {test_query}

ë‹µë³€ A: {response_a.get('answer', 'N/A')}

ë‹µë³€ B: {response_b.get('answer', 'N/A')}

í‰ê°€ ê¸°ì¤€:
1. ì •í™•ì„± (ë‹µë³€ì´ ì§ˆë¬¸ì— ì •í™•íˆ ëŒ€ë‹µí•˜ëŠ”ê°€?)
2. ì™„ì„±ë„ (ë‹µë³€ì´ ì¶©ë¶„íˆ ìƒì„¸í•œê°€?)
3. ìœ ìš©ì„± (ì‹¤ì œë¡œ ë„ì›€ì´ ë˜ëŠ” ì •ë³´ì¸ê°€?)

ì‘ë‹µ í˜•ì‹:
ë‹µë³€ A ì ìˆ˜: X.X/10
ë‹µë³€ B ì ìˆ˜: Y.Y/10
ê°„ëµí•œ ì´ìœ : (í•œ ë‘ ì¤„ë¡œ ì„¤ëª…)
"""
            
            evaluator = ChatOpenAI(
                model_name="gpt-4o-mini",
                temperature=0.1,
                openai_api_key=os.getenv('OPENAI_API_KEY')
            )
            
            evaluation = evaluator.predict(evaluation_prompt)
            
            # ì ìˆ˜ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒŒì‹±)
            import re
            score_a_match = re.search(r'ë‹µë³€ A ì ìˆ˜[:\s]*(\d+\.?\d*)', evaluation)
            score_b_match = re.search(r'ë‹µë³€ B ì ìˆ˜[:\s]*(\d+\.?\d*)', evaluation)
            
            score_a = float(score_a_match.group(1)) if score_a_match else 5.0
            score_b = float(score_b_match.group(1)) if score_b_match else 5.0
            
            # ê²°ê³¼ í¬ë§·íŒ…
            result_text = "ğŸ§ª A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼\\n\\n"
            result_text += f"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {test_query}\\n\\n"
            
            result_text += "ğŸ…°ï¸ ì‹œìŠ¤í…œ A\\n"
            result_text += f"Temperature: {temp_a}\\n"
            result_text += f"Max Tokens: {tokens_a}\\n"
            result_text += f"ëŒ€ìƒ íšŒì‚¬: {', '.join(companies_a)}\\n"
            result_text += f"ì‹¤í–‰ ì‹œê°„: {time_a:.2f}ì´ˆ\\n"
            
            answer_a_clean = response_a.get('answer', 'N/A').replace('**', '').replace('###', '')[:300] + "..."
            result_text += f"ì‘ë‹µ: {answer_a_clean}\\n"
            result_text += f"í’ˆì§ˆ ì ìˆ˜: {score_a:.1f}/10\\n\\n"
            
            result_text += "ğŸ…±ï¸ ì‹œìŠ¤í…œ B\\n"
            result_text += f"Temperature: {temp_b}\\n"
            result_text += f"Max Tokens: {tokens_b}\\n"
            result_text += f"ëŒ€ìƒ íšŒì‚¬: {', '.join(companies_b)}\\n"
            result_text += f"ì‹¤í–‰ ì‹œê°„: {time_b:.2f}ì´ˆ\\n"
            
            answer_b_clean = response_b.get('answer', 'N/A').replace('**', '').replace('###', '')[:300] + "..."
            result_text += f"ì‘ë‹µ: {answer_b_clean}\\n"
            result_text += f"í’ˆì§ˆ ì ìˆ˜: {score_b:.1f}/10\\n\\n"
            
            # ìŠ¹ì ê²°ì •
            if score_a > score_b:
                winner = "ì‹œìŠ¤í…œ A"
                reason = f"ì‹œìŠ¤í…œ Aê°€ {score_a - score_b:.1f}ì  ë” ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤."
            elif score_b > score_a:
                winner = "ì‹œìŠ¤í…œ B"
                reason = f"ì‹œìŠ¤í…œ Bê°€ {score_b - score_a:.1f}ì  ë” ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤."
            else:
                winner = "ë¬´ìŠ¹ë¶€"
                reason = "ë‘ ì‹œìŠ¤í…œì´ ë™ì¼í•œ ì ìˆ˜ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤."
            
            result_text += "ğŸ† ê²°ê³¼\\n"
            result_text += f"ìŠ¹ì: {winner}\\n"
            result_text += f"ì´ìœ : {reason}\\n\\n"
            
            result_text += "ğŸ“Š GPT í‰ê°€ ìƒì„¸:\\n"
            result_text += evaluation.replace('**', '').replace('###', '')
            
            return result_text
            
        except Exception as e:
            return f"âŒ A/B í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _monitoring_loop(self):
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.monitoring_active:
            time.sleep(5)  # 5ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‹¤ì‹œê°„ í†µê³„ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë¡œì§ ì¶”ê°€
    
    def launch(self, **kwargs):
        """ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰"""
        default_kwargs = {
            "server_name": "0.0.0.0",
            "server_port": 7860,
            "share": False,
            "debug": False,
            "show_error": True
        }
        
        # ì‚¬ìš©ì ì„¤ì •ìœ¼ë¡œ ê¸°ë³¸ê°’ ë®ì–´ì“°ê¸°
        launch_kwargs = {**default_kwargs, **kwargs}
        
        self.logger.info(f"Gradio ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰: {launch_kwargs}")
        print(f"ğŸŒ Gradio ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        print(f"ğŸ“ ì£¼ì†Œ: http://localhost:{launch_kwargs['server_port']}")
        
        return self.interface.launch(**launch_kwargs)

def initialize_gradio_interface(dual_agent, feedback_evaluator, company_vector_stores: Dict[str, Any]):
    """Gradio ì¸í„°í˜ì´ìŠ¤ ëª¨ë“ˆ ì´ˆê¸°í™”"""
    print("ğŸŒ Gradio ì¸í„°í˜ì´ìŠ¤ ëª¨ë“ˆ ì´ˆê¸°í™” ì¤‘...")
    
    # ì¸í„°í˜ì´ìŠ¤ ë§¤ë‹ˆì € ìƒì„±
    interface_manager = GradioInterfaceManager(
        dual_agent=dual_agent,
        feedback_evaluator=feedback_evaluator,
        company_vector_stores=company_vector_stores
    )
    
    print("âœ… Gradio ì¸í„°í˜ì´ìŠ¤ ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ!")
    
    return {
        'interface_manager': interface_manager,
        'interface': interface_manager.interface
    }

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„°
    print("ğŸŒ Gradio ì¸í„°í˜ì´ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    dummy_agent = type('DummyAgent', (), {
        'process_question': lambda self, q, c: {
            'answer': 'í…ŒìŠ¤íŠ¸ ë‹µë³€',
            'summary': 'í…ŒìŠ¤íŠ¸ ìš”ì•½', 
            'execution_time': 1.0,
            'success': True
        },
        'get_performance_stats': lambda self: {'í…ŒìŠ¤íŠ¸': 'í†µê³„'}
    })()
    
    dummy_evaluator = type('DummyEvaluator', (), {
        'evaluate_response': lambda self, **kwargs: {'success': True, 'feedback_id': 1, 'evaluation_summary': 'í…ŒìŠ¤íŠ¸'},
        'get_feedback_stats': lambda self: {'í…ŒìŠ¤íŠ¸': 'í”¼ë“œë°±'}
    })()
    
    dummy_stores = {'í…ŒìŠ¤íŠ¸íšŒì‚¬': type('DummyStore', (), {'docstore': type('DummyDocstore', (), {'_dict': {}})()})()}
    
    result = initialize_gradio_interface(dummy_agent, dummy_evaluator, dummy_stores)
    print("âœ… í…ŒìŠ¤íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")