# =========================================
# ğŸ¤– RAG ì‹œìŠ¤í…œ ë° AI ì—ì´ì „íŠ¸ ëª¨ë“ˆ (í–¥ìƒëœ ë²„ì „)
# =========================================

import os
import json
import sqlite3
import logging
import time
import re
import unicodedata
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from pathlib import Path

# LangChain ì„í¬íŠ¸
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferWindowMemory
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate, ChatPromptTemplate
from langchain.schema import Document
from langchain.agents import initialize_agent, Tool, AgentType
from langchain.tools import BaseTool
from langchain.schema.output_parser import StrOutputParser

# ì„¤ì • ì„í¬íŠ¸
try:
    from config.settings import *
except ImportError:
    # ê¸°ë³¸ ì„¤ì •ê°’
    OPENAI_MODEL = "gpt-4o-mini"
    TEMPERATURE = 0.1
    MAX_TOKENS = 1500
    MEMORY_SIZE = 10

class PetInsuranceGuard:
    """ë³´í—˜ ê´€ë ¨ ì§ˆë¬¸ í•„í„°ë§ + ë¶ˆìš©ì–´ ì°¨ë‹¨"""

    def __init__(self, stopwords_path: str = None):
        self.insurance_keywords = [
            "ë³´í—˜", "ë³´ì¥", "ë©´ì±…", "ì²­êµ¬", "ê°€ì…", "ê³„ì•½", "ì•½ê´€", "í˜œíƒ", "ë³´í—˜ë£Œ", "ë‚©ì…",
            "ì¹˜ë£Œ", "ìˆ˜ìˆ ", "ì…ì›", "í†µì›", "ì˜ë£Œ", "ë³‘ì›", "ì§ˆë³‘", "ìƒí•´", "ì‚¬ê³ ", "ë¶€ìƒ",
            "í«", "ë°˜ë ¤ë™ë¬¼", "ê°œ", "ê³ ì–‘ì´", "ë™ë¬¼", "ì• ì™„", "ì˜ë£Œë¹„", "ì¹˜ë£Œë¹„", "ìˆ˜ìˆ ë¹„",
            "ë³´í—˜ê¸ˆ", "ê¸‰ì—¬", "ì§€ê¸‰", "ë°°ìƒ", "ì†í•´", "ë³´ìƒ", "í˜œíƒ", "íŠ¹ì•½", "ë‹´ë³´"
        ]

        # ë¶ˆìš©ì–´ ë¡œë”© (BOM/ì œë¡œí­ê³µë°± ì œê±° + NFC ì •ê·œí™”)
        self.stopwords = set()
        if stopwords_path and os.path.exists(stopwords_path):
            try:
                with open(stopwords_path, "r", encoding="utf-8") as f:
                    for line in f:
                        w = unicodedata.normalize("NFC", line)
                        w = w.replace("\ufeff", "").replace("\u200b", "").strip()
                        if w:
                            self.stopwords.add(w)
                print(f"âœ… ë¶ˆìš©ì–´ {len(self.stopwords)}ê°œ ë¡œë“œ: {stopwords_path}")
            except Exception as e:
                print(f"âš ï¸ ë¶ˆìš©ì–´ íŒŒì¼ì„ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {stopwords_path} / {e}")

    def is_insurance_query(self, text: str) -> bool:
        text_lower = unicodedata.normalize("NFC", text).lower()
        return any(keyword in text_lower for keyword in self.insurance_keywords)

    def contains_stopword(self, text: str) -> bool:
        """ì§ˆë¬¸ì— ë¶ˆìš©ì–´ê°€ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ True (NFC ì •ê·œí™” + ì•ˆì „ ë§¤ì¹­)"""
        if not self.stopwords:
            return False
        t = unicodedata.normalize("NFC", text)
        # ì œë¡œí­/ë¹„ê°€ì‹œ ë¬¸ì ì œê±°
        t = t.replace("\ufeff", "").replace("\u200b", "")
        # ë¬¸ì¥ë¶€í˜¸/íŠ¹ìˆ˜ê¸°í˜¸ë¡œ ë‹¨ì–´ê°€ ìª¼ê°œì ¸ë„ ë§¤ì¹­ë˜ë„ë¡ ê³µë°± ì¹˜í™˜
        norm = re.sub(r"[^\wê°€-í£]", " ", t)
        # ë‹¤ì¤‘ ê³µë°± ì¶•ì•½
        norm = re.sub(r"\s+", " ", norm).strip()

        for w in self.stopwords:
            # ë¶ˆìš©ì–´ë„ ë™ì¼ ì •ê·œí™”/í´ë¦°
            w_norm = unicodedata.normalize("NFC", w).replace("\ufeff", "").replace("\u200b", "").strip()
            if not w_norm:
                continue
            # ë‹¨ìˆœ í¬í•¨ + í† í° ê²½ê³„ ë§¤ì¹­ ë‘˜ ë‹¤ ì‹œë„ (í•œêµ­ì–´ëŠ” \b ê²½ê³„ê°€ ì•½í•´ ë‘˜ ë‹¤ ì‚¬ìš©)
            if w_norm in t:
                return True
            # í† í° ê²½ê³„ ìœ ì‚¬ ë§¤ì¹­
            pattern = rf"(?<!\S){re.escape(w_norm)}(?!\S)"
            if re.search(pattern, norm, flags=re.IGNORECASE):
                return True
        return False


def format_docs(docs):
    """ë¬¸ì„œ í¬ë§·íŒ… í•¨ìˆ˜"""
    formatted_docs = []
    for doc in docs:
        if not hasattr(doc, "page_content"):
            continue
        content = getattr(doc, "page_content", "") or ""
        if isinstance(content, str) and content.strip():
            formatted_docs.append(content.strip())
    return "\n\n".join(formatted_docs)


class PetInsuranceRAGChain:
    """í«ë³´í—˜ íŠ¹í™” RAG ì²´ì¸ (í–¥ìƒëœ ë²„ì „)"""

    def __init__(self, retriever, llm):
        self.retriever = retriever
        self.llm = llm
        self.guard = PetInsuranceGuard()

        # í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.prompt_template = ChatPromptTemplate.from_messages([
            ("system", """
ë„ˆëŠ” í«ë³´í—˜ ì „ë¬¸ ìƒë‹´ì‚¬ì•¼. ì•„ë˜ ì•½ê´€ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´.

ë‹µë³€ ê·œì¹™:
1. ì œê³µëœ ì•½ê´€ ë‚´ìš©ë§Œì„ ê·¼ê±°ë¡œ ë‹µë³€
2. ì•½ê´€ì— ì—†ëŠ” ë‚´ìš©ì€ "ì•½ê´€ì—ì„œ ëª…ì‹œë˜ì§€ ì•ŠìŒ"ì´ë¼ê³  í‘œì‹œ
3. êµ¬ì²´ì ì¸ ì¡°ê±´, í•œë„, ê¸°ê°„ ë“±ì„ í¬í•¨í•˜ì—¬ ìƒì„¸íˆ ì„¤ëª…
4. ì˜ˆì™¸ì‚¬í•­ì´ë‚˜ ì£¼ì˜ì‚¬í•­ë„ í•¨ê»˜ ì•ˆë‚´
5. ì „ë¬¸ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…
6. ë‹µë³€ ëì— ì¶œì²˜ ì •ë³´ë¥¼ ê°„ëµíˆ ì–¸ê¸‰
            """),
            ("human", """
ì•½ê´€ ë‚´ìš©:
{context}

ì§ˆë¬¸: {question}

ìœ„ ì•½ê´€ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
            """)
        ])

    def answer(self, question: str, companies: List[str] = None) -> Dict[str, Any]:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± (ë©€í‹° íšŒì‚¬ ì§€ì›)"""
        # ë³´í—˜ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        if self.guard.contains_stopword(question):
            return {
                "answer": "ì´ ì§ˆë¬¸ì€ í«ë³´í—˜ ì•½ê´€ ë²”ìœ„ ë°–ì˜ ì£¼ì œì—¬ì„œ ë‹µì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "sources": [],
                "companies": companies or ["Unknown"],
            }

        if not self.guard.is_insurance_query(question):
            return {
                "answer": ("ì´ ì§ˆë¬¸ì€ ë³´í—˜ ì•½ê´€ê³¼ ì§ì ‘ ê´€ë ¨ì´ ì—†ì–´, ì•½ê´€ ê¸°ë°˜ RAGë¡œ ë‹µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                          "ì•½ê´€/ë³´ì¥/ë©´ì±…/ì²­êµ¬/í•œë„ ë“± **í«ë³´í—˜ ê´€ë ¨ ì§ˆë¬¸**ì„ ì£¼ì‹œë©´ í•´ë‹¹ íšŒì‚¬ ì•½ê´€ì—ì„œ ì°¾ì•„ ë‹µí•´ë“œë¦´ê²Œìš”."),
                "sources": [],
                "companies": companies or ["Unknown"]
            }

        try:
            # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            docs = self.retriever.get_relevant_documents(question)

            # íšŒì‚¬ í•„í„°ë§ (ë©€í‹° íšŒì‚¬ ì§€ì›)
            if companies:
                docs = [doc for doc in docs if doc.metadata.get("company") in companies]

            if not docs:
                return {
                    "answer": f"ì„ íƒí•œ íšŒì‚¬ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "sources": [],
                    "companies": companies or ["Unknown"]
                }

            # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = format_docs(docs)

            # í”„ë¡¬í”„íŠ¸ ìƒì„± ë° LLM í˜¸ì¶œ
            prompt_input = {
                "context": context,
                "question": question
            }

            prompt = self.prompt_template.format_messages(**prompt_input)
            answer = self.llm.invoke(prompt).content

            # ì†ŒìŠ¤ ì •ë³´ ìˆ˜ì§‘ (í–¥ìƒëœ í˜•ì‹ - ì •í™•í•œ í˜ì´ì§€ ì •ë³´ í¬í•¨)
            sources = []
            companies_found = set()
            for i, doc in enumerate(docs[:5]):  # ìƒìœ„ 5ê°œê¹Œì§€
                company = doc.metadata.get("company", "Unknown")
                companies_found.add(company)
                page = doc.metadata.get("page", "n/a")
                doc_id = doc.metadata.get("doc_id", f"doc_{i+1}")
                
                # í˜ì´ì§€ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° ëª…í™•í•˜ê²Œ í‘œì‹œ
                if page and page != "n/a":
                    source_text = f"{company} ì•½ê´€ {page}í˜ì´ì§€"
                else:
                    source_text = f"{company} ì•½ê´€ (ë¬¸ì„œ ID: {doc_id})"
                
                # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° ì¶”ê°€ (ë” ìƒì„¸í•˜ê²Œ)
                if hasattr(doc, 'page_content') and doc.page_content:
                    preview = doc.page_content[:120].replace('\n', ' ').strip()
                    if preview:
                        source_text += f" - ë‚´ìš©: {preview}..."
                
                sources.append(source_text)

            return {
                "answer": answer,
                "sources": sources,
                "companies": list(companies_found) if companies_found else ["Unknown"],
                "success": True
            }

        except Exception as e:
            print(f"[DEBUG] RAG ì²´ì¸ ì˜¤ë¥˜: {e}")
            return {
                "answer": f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "sources": [],
                "companies": companies or ["Unknown"],
                "success": False,
                "error": str(e)
            }

class DualAgentSystem:
    """ì´ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ"""
    
    def __init__(self, filtered_retrievers: Dict[str, Any]):
        self.filtered_retrievers = filtered_retrievers
        self.llm = self._get_llm()
        self.qa_agent = self._create_qa_agent()
        self.summary_agent = self._create_summary_agent()
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance_log = []
    
    def _get_llm(self):
        """LLM ì„¤ì •"""
        return ChatOpenAI(
            model_name=OPENAI_MODEL,
            temperature=TEMPERATURE,
            max_tokens=MAX_TOKENS,
            openai_api_key=os.getenv('OPENAI_API_KEY')
        )
    
    def _create_qa_agent(self):
        """QA ì—ì´ì „íŠ¸ ìƒì„±"""
        tools = []
        
        # ê²€ìƒ‰ê¸°ê°€ ìˆëŠ”ì§€ í™•ì¸
        if not self.filtered_retrievers:
            print("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ê²€ìƒ‰ê¸°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            # ê¸°ë³¸ ë„êµ¬ ìƒì„±
            def fallback_search(query: str) -> str:
                return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ í«ë³´í—˜ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë°ì´í„° íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            
            tools.append(Tool(
                name="fallback_search",
                func=fallback_search,
                description="í«ë³´í—˜ ì •ë³´ ê²€ìƒ‰ (ê¸°ë³¸)"
            ))
        else:
            for company, retriever in self.filtered_retrievers.items():
                def make_search_func(comp, ret):
                    def search_company(query: str) -> str:
                        try:
                            docs = ret.get_relevant_documents(query)
                            if not docs:
                                return f"{comp}ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                            context = "\n\n".join([
                                f"[{comp}] {doc.page_content}" 
                                for doc in docs[:3]
                            ])
                            return context
                        except Exception as e:
                            return f"{comp} ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
                    return search_company
                
                tools.append(Tool(
                    name=f"search_{company}",
                    func=make_search_func(company, retriever),
                    description=f"{company}ì˜ í«ë³´í—˜ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
                ))
        
        if not tools:
            print("âŒ ë„êµ¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        qa_prompt = """ë‹¹ì‹ ì€ í•œêµ­ì˜ í«ë³´í—˜ ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ìƒì„¸í•œ í•œêµ­ì–´ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        
        ì§ˆë¬¸: {input}
        
        ë‹µë³€ ê·œì¹™:
        - ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•  ê²ƒ
        - ì˜ì–´ë‚˜ ë‹¤ë¥¸ ì–¸ì–´ ì‚¬ìš© ê¸ˆì§€
        - ë³´ì¥ ë²”ìœ„ì™€ ì¡°ê±´ì„ ëª…í™•íˆ ì„¤ëª…
        - ë©´ì±…ì‚¬í•­ê³¼ ì œí•œì‚¬í•­ ì•ˆë‚´
        - íšŒì‚¬ë³„ ì°¨ì´ì ì´ ìˆë‹¤ë©´ ë¹„êµ ì„¤ëª…
        - ì‹¤ìš©ì ì¸ ì¡°ì–¸ ì œê³µ
        - "ì•Œ ìˆ˜ ì—†ë‹¤" ë˜ëŠ” "ì •ë³´ê°€ ì—†ë‹¤"ëŠ” ë‹µë³€ ê¸ˆì§€
        
        {agent_scratchpad}"""
        
        try:
            return initialize_agent(
                tools=tools,
                llm=self.llm,
                agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                verbose=False,
                handle_parsing_errors=True,
                max_iterations=10,  # ë°˜ë³µ íšŸìˆ˜ ì¦ê°€
                max_execution_time=120,  # ìµœëŒ€ ì‹¤í–‰ ì‹œê°„ 2ë¶„
                early_stopping_method="generate"  # ì¡°ê¸° ì¤‘ë‹¨ ì˜µì…˜
            )
        except Exception as e:
            print(f"âŒ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None
    
    def _create_summary_agent(self):
        """ìš”ì•½ ì—ì´ì „íŠ¸ ìƒì„±"""
        summary_prompt = """ë‹¤ìŒ í«ë³´í—˜ ì •ë³´ë¥¼ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

        {text}

        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:
        
        í•µì‹¬ ë‚´ìš©:
        - (ê°„ë‹¨í•˜ê³  ëª…í™•í•œ ìš”ì  3ê°€ì§€)
        
        ì£¼ì˜ì‚¬í•­:
        - (ì£¼ìš” ì œí•œì‚¬í•­ ë° ë©´ì±…ì‚¬í•­)
        
        ì‹¤ìš©ì  ì¡°ì–¸:
        - (êµ¬ì²´ì ì´ê³  ì‹¤ì§ˆì ì¸ ê°€ì´ë“œ)"""
        
        return PromptTemplate(
            template=summary_prompt,
            input_variables=["text"]
        )
    
    def _clean_agent_output(self, raw_output: str) -> str:
        """ì—ì´ì „íŠ¸ ì¶œë ¥ì—ì„œ ëª¨ë“  ë‚´ë¶€ ì²˜ë¦¬ ê³¼ì • ì™„ì „ ì œê±°í•˜ê³  í•œêµ­ì–´ë§Œ ë‚¨ê¸°ê¸°"""
        if not raw_output:
            return "ìš”ì²­í•˜ì‹  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì˜ì–´ ì‘ë‹µì´ë©´ ì¦‰ì‹œ ê¸°ë³¸ í•œêµ­ì–´ ì‘ë‹µìœ¼ë¡œ ëŒ€ì²´
        if any(word in raw_output.lower() for word in ['unable', 'limitations', 'cannot', 'tools', 'i am', 'offers', 'provides', 'including', 'coverage']):
            return "ìš”ì²­í•˜ì‹  í«ë³´í—˜ ì •ë³´ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. êµ¬ì²´ì ì¸ ì¹˜ë£Œë¹„ë‚˜ ë³´ì¥ë²”ìœ„ëŠ” ê° ë³´í—˜íšŒì‚¬ì˜ ì•½ê´€ê³¼ ê°€ì… ì¡°ê±´ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ì •í™•í•œ ì •ë³´ëŠ” í•´ë‹¹ ë³´í—˜íšŒì‚¬ì— ì§ì ‘ ë¬¸ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        
        # ëª¨ë“  ì—ì´ì „íŠ¸ ê´€ë ¨ í‚¤ì›Œë“œì™€ ì˜ì–´ íŒ¨í„´ ì œê±°
        agent_patterns = [
            r'Thought:.*?(?=\n|$)',
            r'Action:.*?(?=\n|$)', 
            r'Action Input:.*?(?=\n|$)',
            r'Observation:.*?(?=\n|$)',
            r'Final Answer:\s*',
            r'I need to.*?(?=\n|$)',
            r'Let me.*?(?=\n|$)',
            r'I am unable.*?(?=\n|$)',
            r'due to limitations.*?(?=\n|$)',
            r'available tools.*?(?=\n|$)',
            r'[0-9]+\. [A-Za-z].*?:',  # ì˜ì–´ ë¦¬ìŠ¤íŠ¸ íŒ¨í„´ ì œê±°
            r'- [A-Z][a-z].*?:',       # ì˜ì–´ í•˜ìœ„ í•­ëª© ì œê±°
            r'Both companies.*?(?=\n|$)',  # ì˜ì–´ ìš”ì•½ë¬¸ ì œê±°
            r'.*[A-Z][a-z]+ [A-Z][a-z]+.*?(?=\n|$)'  # ì˜ì–´ ë¬¸ì¥ íŒ¨í„´ ì œê±°
        ]
        
        cleaned = raw_output
        for pattern in agent_patterns:
            cleaned = re.sub(pattern, '', cleaned, flags=re.DOTALL | re.IGNORECASE)
        
        # í•œêµ­ì–´ê°€ ì•„ë‹Œ ì¤„ë“¤ ì œê±°
        lines = cleaned.split('\n')
        korean_lines = []
        for line in lines:
            line = line.strip()
            if line and any(ord(char) >= 0xAC00 and ord(char) <= 0xD7AF for char in line):  # í•œê¸€ í¬í•¨ ì¤„ë§Œ
                korean_lines.append(line)
        
        cleaned = '\n'.join(korean_lines)
        
        # ë¹ˆ ì¤„ ì •ë¦¬
        cleaned = re.sub(r'\n\s*\n\s*\n+', '\n\n', cleaned)
        cleaned = cleaned.strip()
        
        # ì—¬ì „íˆ ì˜ë¯¸ì—†ëŠ” ë‚´ìš©ì´ë©´ ê¸°ë³¸ ì‘ë‹µ
        if len(cleaned) < 20 or not any(word in cleaned for word in ['ë³´í—˜', 'ë³´ì¥', 'ì¹˜ë£Œ', 'í«', 'ê°•ì•„ì§€', 'ê³ ì–‘ì´']):
            return "í«ë³´í—˜ ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µë“œë¦½ë‹ˆë‹¤. ê° ë³´í—˜íšŒì‚¬ë§ˆë‹¤ ë³´ì¥ ë²”ìœ„ì™€ ì¡°ê±´ì´ ë‹¤ë¥´ë¯€ë¡œ, ìƒì„¸í•œ ë‚´ìš©ì€ í•´ë‹¹ ë³´í—˜íšŒì‚¬ ì•½ê´€ì„ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        
        return cleaned

    def _format_sources(self, companies: List[str]) -> List[Dict[str, str]]:
        """ì¶œì²˜ ì •ë³´ë¥¼ ëª…í™•í•˜ê²Œ í¬ë§·íŒ… - ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜"""
        sources = []
        
        if not companies:
            companies = ['ì¢…í•©']
        
        # ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰í•˜ì—¬ ì†ŒìŠ¤ ì •ë³´ ì–»ê¸°
        for i, company in enumerate(companies, 1):
            if company == 'ì¢…í•©':
                source_info = {
                    'company': 'ì „ì²´ ë³´í—˜íšŒì‚¬',
                    'document': 'í«ë³´í—˜ ì•½ê´€ ì¢…í•©',
                    'page': 'Multiple',
                    'description': 'ì—¬ëŸ¬ ë³´í—˜íšŒì‚¬ì˜ í«ë³´í—˜ ì•½ê´€ì„ ì¢…í•©í•˜ì—¬ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.'
                }
            else:
                # í•´ë‹¹ íšŒì‚¬ì˜ retrieverë¡œ ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰
                if company in self.filtered_retrievers:
                    try:
                        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë¡œ ì‹¤ì œ ë¬¸ì„œ ì •ë³´ ì–»ê¸°
                        docs = self.filtered_retrievers[company].get_relevant_documents("í«ë³´í—˜ ì•½ê´€")
                        
                        # ì‹¤ì œ í˜ì´ì§€ ì •ë³´ ìˆ˜ì§‘
                        page_numbers = []
                        for doc in docs[:3]:  # ìƒìœ„ 3ê°œ ë¬¸ì„œë§Œ
                            if hasattr(doc, 'metadata') and 'page' in doc.metadata:
                                page_numbers.append(str(doc.metadata['page']))
                        
                        page_info = ', '.join(page_numbers) if page_numbers else 'Multiple'
                        
                        source_info = {
                            'company': company,
                            'document': f'{company} í«ë³´í—˜ ì•½ê´€',
                            'page': page_info,
                            'description': f'{company} í«ë³´í—˜ì˜ ë³´ì¥ë‚´ìš©, ë©´ì±…ì‚¬í•­, ê°€ì…ì¡°ê±´ ë“±ì„ ì°¸ì¡°í–ˆìŠµë‹ˆë‹¤.'
                        }
                    except Exception:
                        # ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì •ë³´
                        source_info = {
                            'company': company,
                            'document': f'{company} í«ë³´í—˜ ì•½ê´€',
                            'page': 'N/A',
                            'description': f'{company} í«ë³´í—˜ ê´€ë ¨ ì •ë³´ë¥¼ ì°¸ì¡°í–ˆìŠµë‹ˆë‹¤.'
                        }
                else:
                    source_info = {
                        'company': company,
                        'document': f'{company} í«ë³´í—˜ ì•½ê´€',
                        'page': 'N/A',
                        'description': f'{company} í«ë³´í—˜ ê´€ë ¨ ì •ë³´ë¥¼ ì°¸ì¡°í–ˆìŠµë‹ˆë‹¤.'
                    }
            
            sources.append(source_info)
        
        return sources

    def process_question(self, question: str, companies: List[str] = None) -> Dict[str, Any]:
        """ì§ˆë¬¸ ì²˜ë¦¬"""
        start_time = datetime.now()
        
        try:
            # QA ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if self.qa_agent is None:
                qa_result = "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë°ì´í„° íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                sources = []
            else:
                # ë‹¤ì¤‘ íšŒì‚¬ ì§€ì›ì„ ìœ„í•œ ì§ˆë¬¸ ìˆ˜ì •
                if companies:
                    company_context = f"ë‹¤ìŒ íšŒì‚¬ë“¤ì˜ ì •ë³´ë¥¼ ì°¸ì¡°í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”: {', '.join(companies)}. "
                    enhanced_question = company_context + question
                else:
                    enhanced_question = question
                
                # QA ì—ì´ì „íŠ¸ë¡œ ë‹µë³€ ìƒì„±
                raw_qa_result = self.qa_agent.run(enhanced_question)
                
                # ì—ì´ì „íŠ¸ ì¶œë ¥ ì •ë¦¬
                qa_result = self._clean_agent_output(raw_qa_result)
                
                # ì¶œì²˜ ì •ë³´ ìƒì„±
                sources = self._format_sources(companies)
            
            # ìš”ì•½ ì—ì´ì „íŠ¸ë¡œ ìš”ì•½ ìƒì„±
            summary_prompt = self.summary_agent.format(text=qa_result)
            summary_result = self.llm.predict(summary_prompt)
            
            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            execution_time = (datetime.now() - start_time).total_seconds()
            
            # ì„±ëŠ¥ ë¡œê·¸ ê¸°ë¡
            log_entry = {
                "timestamp": start_time.isoformat(),
                "question": question,
                "companies": companies,
                "execution_time": execution_time,
                "success": True
            }
            self.performance_log.append(log_entry)
            
            return {
                "answer": qa_result,
                "summary": summary_result,
                "sources": sources,
                "execution_time": execution_time,
                "success": True,
                "error": None
            }
            
        except Exception as e:
            # ì—ëŸ¬ ë¡œê·¸ ê¸°ë¡
            execution_time = (datetime.now() - start_time).total_seconds()
            log_entry = {
                "timestamp": start_time.isoformat(),
                "question": question,
                "companies": companies,
                "execution_time": execution_time,
                "success": False,
                "error": str(e)
            }
            self.performance_log.append(log_entry)
            
            return {
                "answer": f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "summary": "ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "execution_time": execution_time,
                "success": False,
                "error": str(e)
            }
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        if not self.performance_log:
            return {"message": "ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        total_queries = len(self.performance_log)
        successful_queries = sum(1 for log in self.performance_log if log["success"])
        avg_time = sum(log["execution_time"] for log in self.performance_log) / total_queries
        
        return {
            "total_queries": total_queries,
            "successful_queries": successful_queries,
            "success_rate": successful_queries / total_queries * 100,
            "average_execution_time": avg_time,
            "recent_logs": self.performance_log[-5:]
        }

class UserFeedbackEvaluator:
    """ì‚¬ìš©ì í”¼ë“œë°± í‰ê°€ ë° ì €ì¥ ì‹œìŠ¤í…œ"""
    
    def __init__(self, db_path: str = "user_feedback.db"):
        self.db_path = db_path
        self._init_database()
        self.evaluation_criteria = {
            "ì •í™•ì„±": "ë‹µë³€ì´ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ê°€?",
            "ì™„ì„±ë„": "ë‹µë³€ì´ ì¶©ë¶„í•˜ê³  í¬ê´„ì ì¸ê°€?", 
            "ëª…í™•ì„±": "ë‹µë³€ì´ ì´í•´í•˜ê¸° ì‰½ê³  ëª…í™•í•œê°€?",
            "ì‹¤ìš©ì„±": "ë‹µë³€ì´ ì‹¤ì œë¡œ ë„ì›€ì´ ë˜ëŠ”ê°€?",
            "ì¹œê·¼í•¨": "ë‹µë³€ì´ ì¹œê·¼í•˜ê³  ì ‘ê·¼í•˜ê¸° ì‰¬ìš´ê°€?"
        }
    
    def _init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS feedback (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                question TEXT NOT NULL,
                answer TEXT NOT NULL,
                accuracy_score INTEGER,
                completeness_score INTEGER,
                clarity_score INTEGER,
                usefulness_score INTEGER,
                friendliness_score INTEGER,
                overall_score REAL,
                comments TEXT,
                company TEXT,
                session_id TEXT
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def evaluate_response(self, 
                         question: str, 
                         answer: str, 
                         scores: Dict[str, int],
                         comments: str = "",
                         company: str = "",
                         session_id: str = "") -> Dict[str, Any]:
        """ì‘ë‹µ í‰ê°€ ë° ì €ì¥"""
        
        # ì ìˆ˜ ê²€ì¦
        for criterion, score in scores.items():
            if not (1 <= score <= 5):
                return {
                    "success": False,
                    "error": f"{criterion} ì ìˆ˜ëŠ” 1-5 ë²”ìœ„ì—¬ì•¼ í•©ë‹ˆë‹¤."
                }
        
        # ì „ì²´ í‰ê·  ì ìˆ˜ ê³„ì‚°
        overall_score = sum(scores.values()) / len(scores)
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO feedback (
                    question, answer, accuracy_score, completeness_score,
                    clarity_score, usefulness_score, friendliness_score,
                    overall_score, comments, company, session_id
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                question, answer,
                scores.get("ì •í™•ì„±", 3),
                scores.get("ì™„ì„±ë„", 3), 
                scores.get("ëª…í™•ì„±", 3),
                scores.get("ì‹¤ìš©ì„±", 3),
                scores.get("ì¹œê·¼í•¨", 3),
                overall_score, comments, company, session_id
            ))
            
            feedback_id = cursor.lastrowid
            conn.commit()
            conn.close()
            
            return {
                "success": True,
                "feedback_id": feedback_id,
                "overall_score": overall_score,
                "evaluation_summary": self._generate_evaluation_summary(scores, overall_score)
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨: {str(e)}"
            }
    
    def _generate_evaluation_summary(self, scores: Dict[str, int], overall_score: float) -> str:
        """í‰ê°€ ìš”ì•½ ìƒì„±"""
        high_scores = [k for k, v in scores.items() if v >= 4]
        low_scores = [k for k, v in scores.items() if v <= 2]
        
        summary = f"ì „ì²´ í‰ì : {overall_score:.1f}/5.0\n"
        
        if high_scores:
            summary += f"ê°•ì : {', '.join(high_scores)}\n"
        
        if low_scores:
            summary += f"ê°œì„  í•„ìš”: {', '.join(low_scores)}\n"
        
        if overall_score >= 4.0:
            summary += "ë§¤ìš° ë§Œì¡±ìŠ¤ëŸ¬ìš´ ë‹µë³€ì…ë‹ˆë‹¤! ğŸ‘"
        elif overall_score >= 3.0:
            summary += "ì–‘í˜¸í•œ ë‹µë³€ì…ë‹ˆë‹¤. ğŸ“"
        else:
            summary += "ë‹µë³€ í’ˆì§ˆ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. ğŸ”§"
        
        return summary
    
    def get_feedback_stats(self, days: int = 30) -> Dict[str, Any]:
        """í”¼ë“œë°± í†µê³„ ì¡°íšŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT 
                    COUNT(*) as total_feedback,
                    AVG(overall_score) as avg_score,
                    AVG(accuracy_score) as avg_accuracy,
                    AVG(completeness_score) as avg_completeness,
                    AVG(clarity_score) as avg_clarity,
                    AVG(usefulness_score) as avg_usefulness,
                    AVG(friendliness_score) as avg_friendliness
                FROM feedback 
                WHERE timestamp >= datetime('now', '-{} days')
            '''.format(days))
            
            stats = cursor.fetchone()
            
            # íšŒì‚¬ë³„ í†µê³„
            cursor.execute('''
                SELECT company, COUNT(*), AVG(overall_score)
                FROM feedback 
                WHERE timestamp >= datetime('now', '-{} days')
                AND company != ''
                GROUP BY company
            '''.format(days))
            
            company_stats = cursor.fetchall()
            conn.close()
            
            return {
                "period_days": days,
                "total_feedback": stats[0] or 0,
                "average_overall_score": round(stats[1] or 0, 2),
                "criteria_scores": {
                    "ì •í™•ì„±": round(stats[2] or 0, 2),
                    "ì™„ì„±ë„": round(stats[3] or 0, 2),
                    "ëª…í™•ì„±": round(stats[4] or 0, 2),
                    "ì‹¤ìš©ì„±": round(stats[5] or 0, 2),
                    "ì¹œê·¼í•¨": round(stats[6] or 0, 2)
                },
                "company_performance": [
                    {
                        "company": comp,
                        "feedback_count": count,
                        "average_score": round(avg, 2)
                    }
                    for comp, count, avg in company_stats
                ]
            }
            
        except Exception as e:
            return {
                "error": f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
            }

def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_dir / "rag_system.log"),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger(__name__)

def initialize_rag_functions(filtered_retrievers: Dict[str, Any]):
    """RAG í•¨ìˆ˜ ëª¨ë“ˆ ì´ˆê¸°í™”"""
    print("ğŸ¤– RAG í•¨ìˆ˜ ëª¨ë“ˆ ì´ˆê¸°í™” ì¤‘...")
    
    # ë¡œê¹… ì„¤ì •
    logger = setup_logging()
    
    # API í‚¤ í™•ì¸ (í™˜ê²½ë³€ìˆ˜ ìš°ì„ )
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        # ë°±ì—…: openaikey.txt íŒŒì¼ì—ì„œ ì½ê¸° ì‹œë„
        try:
            with open('openaikey.txt', 'r') as f:
                api_key = f.read().strip()
            os.environ['OPENAI_API_KEY'] = api_key
            logger.info("OpenAI API í‚¤ë¥¼ ë°±ì—… íŒŒì¼ì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        except FileNotFoundError:
            raise ValueError(
                "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:\n"
                "1. .env íŒŒì¼ì— OPENAI_API_KEY=your-key ì¶”ê°€\n"
                "2. í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY ì„¤ì •\n"
                "3. openaikey.txt íŒŒì¼ ìƒì„±"
            )
    else:
        logger.info("OpenAI API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    
    # ì´ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    dual_agent = DualAgentSystem(filtered_retrievers)
    
    # í”¼ë“œë°± í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    feedback_evaluator = UserFeedbackEvaluator()
    
    # íšŒì‚¬ë³„ RAG ì²´ì¸ ìƒì„±
    rag_chains = {}
    for company, retriever in filtered_retrievers.items():
        try:
            # LLM ìƒì„±
            llm = ChatOpenAI(
                model_name=OPENAI_MODEL,
                temperature=TEMPERATURE,
                max_tokens=MAX_TOKENS,
                openai_api_key=os.getenv('OPENAI_API_KEY')
            )
            rag_chains[company] = PetInsuranceRAGChain(retriever, llm)
        except Exception as e:
            logger.error(f"íšŒì‚¬ {company}ì˜ RAG ì²´ì¸ ìƒì„± ì‹¤íŒ¨: {e}")
    
    logger.info("RAG í•¨ìˆ˜ ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ!")
    
    return {
        'dual_agent': dual_agent,
        'feedback_evaluator': feedback_evaluator,
        'rag_chains': rag_chains,
        'logger': logger
    }

def enhanced_build_reply_and_entries(user_query: str, companies: list, alpha: float, show_sources: bool, rag_chains: dict, monitor=None):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì´ í¬í•¨ëœ í–¥ìƒëœ ì‘ë‹µ ìƒì„±"""
    companies = companies or list(rag_chains.keys())
    blocks, entries = [], []

    for company in companies:
        start_time = time.time()
        success = False
        error_type = None

        try:
            if company not in rag_chains:
                blocks.append(f"### {company}\ní•´ë‹¹ íšŒì‚¬ì˜ RAG ì²´ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                error_type = "rag_chain_missing"
                continue

            # RAG ì²´ì¸ìœ¼ë¡œ ë‹µë³€ ìƒì„±
            rag_chain = rag_chains[company]
            result = rag_chain.answer(user_query, [company])

            if result.get("success", True):
                answer = result['answer']
                sources = result.get('sources', [])
                
                # ë‹µë³€ í‘œì‹œ
                blocks.append(f"### {company}")
                blocks.append(answer)

                # ì¶œì²˜ ì •ë³´ í‘œì‹œ
                if show_sources and sources:
                    blocks.append("\n**ğŸ“‹ ì¶œì²˜:**")
                    for i, src in enumerate(sources[:3], 1):
                        doc_id = src.get('doc_id', 'unknown')
                        page = src.get('page', 'n/a')
                        page_str = f"p.{page}" if page not in (None, "n/a") else "p.n/a"
                        blocks.append(f"  {i}. {doc_id} / {page_str}")

                blocks.append("---")
                
                # ì—”íŠ¸ë¦¬ ì¶”ê°€
                entries.append({
                    "user_query": user_query,
                    "company": company,
                    "answer": answer,
                    "sources": [f"{s.get('doc_id', 'unknown')} / p.{s.get('page', 'n/a')}" for s in sources[:3]]
                })
                
                success = True
            else:
                error_msg = result.get('error', 'Unknown error')
                blocks.append(f"### {company}\nâŒ ì˜¤ë¥˜: {error_msg}")
                error_type = "rag_error"

        except Exception as e:
            blocks.append(f"### {company}\nâŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            error_type = "processing_error"

        finally:
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            response_time = time.time() - start_time
            if monitor:
                monitor.log_query(user_query, company, response_time, success, error_type)

    final_reply = "\n\n".join(blocks) if blocks else "ì„ íƒí•œ íšŒì‚¬ì—ì„œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    return final_reply, entries


def generate_summary_and_recommendation(qa_entries: list, llm=None) -> str:
    """QA ì—”íŠ¸ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìš”ì•½ ë° ì¶”ì²œ ìƒì„±"""
    if not qa_entries:
        return "ì§ˆë¬¸/ë‹µë³€ ê¸°ë¡ì´ ì—†ì–´ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    if llm is None:
        llm = ChatOpenAI(
            model_name=OPENAI_MODEL,
            temperature=0.1,
            max_tokens=1500,
            openai_api_key=os.getenv('OPENAI_API_KEY')
        )

    # QA ì—”íŠ¸ë¦¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    dossier = []
    for entry in qa_entries:
        dossier.append(f"[ì§ˆë¬¸] {entry['user_query']}")
        dossier.append(f"[{entry['company']}] {entry['answer']}")
        if entry.get('sources'):
            dossier.append(f"  ì¶œì²˜: {', '.join(entry['sources'])}")
        dossier.append("")

    dossier_text = "\n".join(dossier)
    k_reco = min(3, len(set(entry['company'] for entry in qa_entries)))

    # ìš”ì•½ í”„ë¡¬í”„íŠ¸
    summary_prompt = ChatPromptTemplate.from_messages([
        ("system", """
ë„ˆëŠ” í«ë³´í—˜ ì „ë¬¸ê°€ì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸/ë‹µë³€ ê¸°ë¡ì„ ë¶„ì„í•´ì„œ ì¢…í•©ì ì¸ ìš”ì•½ê³¼ ì¶”ì²œì„ ì œê³µí•´.

ë¶„ì„ ìš”êµ¬ì‚¬í•­:
1. íšŒì‚¬ë³„ ë³´ì¥ ë‚´ìš© ì°¨ì´ì  ë¹„êµ
2. ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ì í•©í•œ ìƒìœ„ {k_reco}ê°œ íšŒì‚¬ ì¶”ì²œ
3. ê° íšŒì‚¬ì˜ ì¥ë‹¨ì  ì„¤ëª…
4. ì‹¤ìš©ì ì¸ ê°€ì… ì¡°ì–¸

ë‹µë³€ í˜•ì‹:
## ğŸ† ì¶”ì²œ ë³´í—˜ì‚¬ ìˆœìœ„
### 1ìœ„: [íšŒì‚¬ëª…] - ì¶”ì²œ ì´ìœ 
### 2ìœ„: [íšŒì‚¬ëª…] - ì¶”ì²œ ì´ìœ 
### 3ìœ„: [íšŒì‚¬ëª…] - ì¶”ì²œ ì´ìœ 

## ğŸ“Š íšŒì‚¬ë³„ íŠ¹ì§• ë¹„êµ
[ê° íšŒì‚¬ì˜ ì£¼ìš” íŠ¹ì§•ê³¼ ì°¨ì´ì ]

## ğŸ’¡ ê°€ì… ì‹œ ê³ ë ¤ì‚¬í•­
[ì‹¤ìš©ì ì¸ ì¡°ì–¸ê³¼ ì£¼ì˜ì‚¬í•­]
        """),
        ("human", """
ë‹¤ìŒì€ ì‚¬ìš©ìì˜ í«ë³´í—˜ ì§ˆë¬¸/ë‹µë³€ ê¸°ë¡ì´ì•¼:

{dossier}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¢…í•© ë¶„ì„ê³¼ ì¶”ì²œì„ í•´ì¤˜.
        """)
    ])

    try:
        result = llm.invoke(summary_prompt.format_messages(dossier=dossier_text, k_reco=k_reco))
        return result.content
    except Exception as e:
        return f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„°
    dummy_retrievers = {"í…ŒìŠ¤íŠ¸íšŒì‚¬": None}
    result = initialize_rag_functions(dummy_retrievers)
    print(f"ğŸ¤– RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ: {len(result)}ê°œ ì»´í¬ë„ŒíŠ¸")